{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted all SourceForge URLs.\n",
      "Inserted all GitLab URLs.\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# Name: Daniel Barry\n",
    "# Professor: Dr. Audris Mockus\n",
    "# Date: 10/15/2018\n",
    "# MiniProject2\n",
    "# The purpose of this code is to store\n",
    "# the URLs from the project discovery\n",
    "# in the class database.\n",
    "########################################\n",
    "\n",
    "import pymongo\n",
    "\n",
    "## Database information for storage of discovery results.\n",
    "dbname = \"fdac18mp2\"\n",
    "sfcollname = \"sfprj_dbarry\"\n",
    "glcollname = \"glprj_dbarry\"\n",
    "\n",
    "client = pymongo.MongoClient(host='da1')\n",
    "db = client[dbname]\n",
    "\n",
    "## Switch to SourceForge database.\n",
    "coll = db[sfcollname]\n",
    "\n",
    "## Read-in the URLs from the SourceForge list.\n",
    "f = open(\"dbarry_sf_list.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "## Store the URLs from the SourceForge List.\n",
    "for line in lines:\n",
    "        word = line.split()\n",
    "        coll.insert_one({\"url\": word[2]})\n",
    "\n",
    "print(\"Inserted all SourceForge URLs.\")\n",
    "\n",
    "## Switch to GitLab database.\n",
    "coll = db[glcollname]\n",
    "\n",
    "## Read-in the URLs from the GitLab list.\n",
    "f = open(\"dbarry_gl_list.txt\", 'r')\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "\n",
    "## Store the URLs from the GitLab List.\n",
    "for line in lines:\n",
    "        word = line.split()\n",
    "        coll.insert_one({\"url\": word[0]})\n",
    "\n",
    "print(\"Inserted all GitLab URLs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json, pymongo, time, datetime, re, requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "#for da2 \n",
    "#client = pymongo .MongoClient (host=\"da1.eecs.utk.edu\")\n",
    "#for gcloud machine\n",
    "client = pymongo .MongoClient (host='da1')\n",
    "\n",
    "db = client ['fdac18mp2']\n",
    "\n",
    "#replace audris with your utkid\n",
    "coll = db['npm_dbarry']\n",
    "\n",
    "pre = 'https://api.npms.io/v2/package/'\n",
    "\n",
    "def output(s, p):\n",
    " print(str(s) + \";\" + p)\n",
    "\n",
    "for pname in sys.stdin.readlines():\n",
    " pname = pname.strip('\\n')\n",
    " #Thks @Macbrine: url parameters need to be quoted\n",
    " pname  = quote(pname, safe='')\n",
    " r = requests.get(pre + pname)\n",
    " if(r.ok):\n",
    "  result = r.content\n",
    "  try:\n",
    "   result_json = json.loads(result.decode('ascii', errors='ignore'))\n",
    "   #modify keys to remove unwanted '$' '.' characters that mongodb does not allow\n",
    "   r1 = {}\n",
    "   for k in result_json:\n",
    "    k1 = k.replace('$', 'DOLLARSIGN')\n",
    "    k1 = k1.replace('.', 'PERIODSIGN')\n",
    "    r1 [k1] = result_json [k]\n",
    "   coll .insert (r1, check_keys=False)\n",
    "   output (0, pname)\n",
    "  except:\n",
    "   e = sys.exc_info()[0]\n",
    "   output (e, pname)\n",
    " else:\n",
    "  output (r .ok, pname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, pymongo, json, time\n",
    "import datetime\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import requests\n",
    "gleft = 15\n",
    "client = pymongo.MongoClient (host='da1')\n",
    "#client = pymongo.MongoClient (host=\"da1.eecs.utk.edu\")\n",
    "login = \"dbarry9\"\n",
    "passwd = sys.argv[1]\n",
    "\n",
    "baseurl = 'https://api.github.com/repos'\n",
    "headers = {'Accept': 'application/vnd.github.v3.star+json'}\n",
    "headers = {'Accept': 'application/vnd.github.hellcat-preview+json'}\n",
    "\n",
    "db = client['fdac18mp2']\n",
    "collName = 'releases_dbarry'\n",
    "coll = db [collName]\n",
    "def wait (left):\n",
    "  while (left < 20):\n",
    "    l = requests .get('https://api.github.com/rate_limit', auth=(login,passwd))\n",
    "    if (l.ok):\n",
    "      left = int (l.headers.get ('X-RateLimit-Remaining'))\n",
    "      reset = int (l.headers.get ('x-ratelimit-reset'))\n",
    "      now = int (time.time ())\n",
    "      dif = reset - now\n",
    "      if (dif > 0 and left < 20):\n",
    "        sys.stderr.write (\"waiting for \" + str (dif) + \"s until\"+str(left)+\"s\\n\")\n",
    "        time .sleep (dif)\n",
    "    time .sleep (0.5)\n",
    "  return left  \n",
    "\n",
    "def get (url):\n",
    "  global gleft\n",
    "  gleft = wait (gleft)\n",
    "  values = []\n",
    "  size = 0\n",
    "  # sys.stderr.write (\"left:\"+ str(left)+\"s\\n\")\n",
    "  try: \n",
    "    r = requests .get (url, headers=headers, auth=(login, passwd))\n",
    "    time .sleep (0.5)\n",
    "    if (r.ok):\n",
    "      gleft = int(r.headers.get ('X-RateLimit-Remaining'))\n",
    "      lll = r.headers.get ('Link')\n",
    "      links = ['']\n",
    "      if lll is not None: \n",
    "        links = lll.split(',')\n",
    "      t = r.text\n",
    "      size += len (t)\n",
    "      try:\n",
    "        array = json .loads (t)\n",
    "        for el in array:\n",
    "          values .append (el)\n",
    "      except Exception as e:\n",
    "        sys.stderr.write(str(e)+\" in json .loads\\n\")\n",
    "      #t = r.text.encode ('utf-8')\n",
    "      while '; rel=\"next\"' in  links[0]:\n",
    "        gleft = int(r.headers.get ('X-RateLimit-Remaining'))\n",
    "        gleft = wait (gleft)\n",
    "        url = links[0] .split(';')[0].replace('<','').replace('>','');\n",
    "        try: \n",
    "          r = requests .get(url, headers=headers, auth=(login, passwd))\n",
    "          if (r.ok): \n",
    "            lll = r.headers.get ('Link')\n",
    "            links = ['']\n",
    "            if lll is not None: \n",
    "              links = lll .split(',')\n",
    "            t = r.text\n",
    "            size += len (t)\n",
    "            try:\n",
    "              array = json.loads (t)\n",
    "              for el in array:\n",
    "                values .append (el)\n",
    "              print ('in load next: ' + str(len (values)))\n",
    "            except Exception as e:\n",
    "              sys.stderr.write(str(e)+\" in json .loads next\\n\")\n",
    "          else:\n",
    "            links = ['']\n",
    "        except requests.exceptions.ConnectionError:\n",
    "          sys.stderr.write('could not get ' + links + ' for '+ url + '\\n')   \n",
    "          #print u';'.join((u, repo, t)).encode('utf-8') \n",
    "      try: \n",
    "        print (url + ';' + str(values))\n",
    "      except Exception as e:\n",
    "        sys.stderr.write(str(e)+\" in print \" + url + \"\\n\")\n",
    "    else:\n",
    "      print (url + ';ERROR r not ok')\n",
    "  except requests.exceptions.ConnectionError:\n",
    "    print (url + ';ERROR ConnectionError')\n",
    "  print ('returning nkeys=' + str(len (values)))\n",
    "  return values, size\n",
    "\n",
    "def chunks(l, n):\n",
    "  if n < 1: n = 1\n",
    "  return [l[i:i + n] for i in range(0, len(l), n)]\n",
    "\n",
    "#def getReleases(n):\n",
    "for n in sys.stdin.readlines():\n",
    "  #first clean the url\n",
    "  n = re.sub(\"^.*github.com/\",\"\",n)\n",
    "  n = re.sub(\"\\.git$\",\"\",n)\n",
    "  url = baseurl + '/' + n + '/releases'\n",
    "  url1 = url\n",
    "  v = []\n",
    "  size = 0\n",
    "  try: \n",
    "    v, size = get (url1)\n",
    "    print (str (len (v)) + ';' + str (size) + ';' + url1)\n",
    "    sys .stdout .flush ()\n",
    "  except Exception as e:\n",
    "    sys.stderr.write (\"Could not get:\" + url1 + \". Exception:\" + str(e) + \"\\n\")\n",
    "    continue\n",
    "  print (url1 + ' after exception lenv(v)=' + str(len (v)))\n",
    "  ts = datetime.datetime.utcnow()\n",
    "  if len (v) > 0:\n",
    "    # size may be bigger in bson, factor of 2 doesnot always suffice -- the 'else' clause is UNLIKELY  \n",
    "    if (size < 16777216/3):\n",
    "      #print (v)\n",
    "      coll.insert_one ( { 'name': n, 'url': url, 'utc':ts, 'values': v } )\n",
    "    else:\n",
    "      s = size;\n",
    "      n = 3*s/16777216\n",
    "      i = 0\n",
    "      for ch in chunks (v, n):\n",
    "        coll.insert_one ( { 'chunk': i, 'name':n, 'url': url, 'utc':ts, 'values': ch } )\n",
    "        i = i + 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
