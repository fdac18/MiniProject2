{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792\n"
     ]
    }
   ],
   "source": [
    "'''The below cell was used to load some gitlab  repos. It was obviously based on the\n",
    "   sample code on the class repo. I have commented out the portion that actually does\n",
    "   the loading so I won't just load mutiple version of the same repos documents after\n",
    "   doing so many times before I realized what I was actually doing. If you want you can\n",
    "   uncomment this portion to check that it works. I also added a line to clear out my \n",
    "   collection. I did this after I realized what I had done when I checked the number of\n",
    "   documents in my collection and found that there were over 30000. I then commented \n",
    "   this out and ran the get method again to reload the collection. I then commented that\n",
    "   out as stated above.\n",
    "   Other relevant notes:\n",
    "       line 24: This is were I cleared out my collection so I could start from scratch\n",
    "               ----Currently commented out\n",
    "       line 107: This is were I load the gitlab documents representing projects\n",
    "               ----Currently commented out\n",
    "'''\n",
    "\n",
    "#the below code was used to load a bunch of the projects from git lab\n",
    "import sys\n",
    "import re\n",
    "import pymongo\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "\n",
    "dbname = \"fdac18mp2\" #please use this database\n",
    "collname = \"glprj_gjones2\" #please modify so you store data in your collection\n",
    "# beginning page index\n",
    "begin = \"0\"\n",
    "\n",
    "# start pymongo client\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "db = client[dbname]\n",
    "\n",
    "coll = db[collname]\n",
    "\n",
    "#coll.delete_many({})\n",
    "\n",
    "print(coll.count_documents({}))\n",
    "\n",
    "beginurl = \"https://gitlab.com/api/v4/projects?archived=false&membership=false&order_by=created_at&owned=false&page=\" + begin + \\\n",
    "    \"&per_page=99&simple=false&sort=desc&starred=false&statistics=false&with_custom_attributes=false&with_issues_enabled=false&with_merge_requests_enabled=false\"\n",
    "\n",
    "gleft = 0\n",
    "\n",
    "header = {'per_page': 99}\n",
    "\n",
    "# check remaining query chances for rate-limit restriction\n",
    "def wait(left):\n",
    "    global header\n",
    "    while (left < 20):\n",
    "        l = requests.get('https://gitlab.com/api/v4/projects', headers=header)\n",
    "        if (l.ok):\n",
    "            left = int(l.headers.get('RateLimit-Remaining'))\n",
    "        time .sleep(60)\n",
    "    return left\n",
    "\n",
    "\n",
    "# send queries and extract urls \n",
    "def get(url, coll):\n",
    "\n",
    "    global gleft\n",
    "    global header\n",
    "    global bginnum\n",
    "    gleft = wait(gleft)\n",
    "    values = []\n",
    "    size = 0\n",
    "\n",
    "    try:\n",
    "        r = requests .get(url, headers=header)\n",
    "        time .sleep(0.5)\n",
    "        # got blocked\n",
    "        if r.status_code == 403:\n",
    "            return \"got blocked\", str(bginnum)\n",
    "        if (r.ok):\n",
    "\n",
    "            gleft = int(r.headers.get('RateLimit-Remaining'))\n",
    "            lll = r.headers.get('Link')\n",
    "            t = r.text\n",
    "            array = json.loads(t)\n",
    "            \n",
    "            for el in array:\n",
    "                coll.insert_one(el)\n",
    " \n",
    "            #next page\n",
    "            while ('; rel=\"next\"' in lll):\n",
    "                gleft = int(r.headers.get('RateLimit-Remaining'))\n",
    "                gleft = wait(gleft)\n",
    "                # extract next page url\n",
    "                ll = lll.replace(';', ',').split(',')\n",
    "                url = ll[ll.index(' rel=\"next\"') -\n",
    "                         1].replace('<', '').replace('>', '').lstrip()\n",
    "             \n",
    "                try:\n",
    "                    r = requests .get(url, headers=header)\n",
    "                    if r.status_code == 403:\n",
    "                        return \"got blocked\", str(bginnum)\n",
    "                    if (r.ok):\n",
    "                        lll = r.headers.get('Link')\n",
    "                        t = r.text\n",
    "                        array1 = json.loads(t)\n",
    "                        for el in array1:\n",
    "                            coll.insert_one(el)\n",
    "                    else:\n",
    "                        sys.stderr.write(\"url can not found2:\\n\" + url + '\\n')\n",
    "                        return \n",
    "                except requests.exceptions.ConnectionError:\n",
    "                    sys.stderr.write('could not get ' + url + '\\n')\n",
    "\n",
    "        else:\n",
    "            sys.stderr.write(\"url can not found1:\\n\" + url + '\\n')\n",
    "            return\n",
    "\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        sys.stderr.write('could not get ' + url + '\\n')\n",
    "    except Exception as e:\n",
    "        sys.stderr.write(url + ';' + str(e) + '\\n')\n",
    "\n",
    "#start retrieving        \n",
    "#get(beginurl,coll)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 860 total documents in the collection glprj_gjones2\n",
      "there are 68 source forge projects\n",
      "there are 792 gitlab projects\n",
      "there are 860 projects that start with n\n",
      "the length of the to keep array is 860\n"
     ]
    }
   ],
   "source": [
    "'''The below cell at one point looked through the loaded gitlab project documents and found all of those\n",
    "   projects that have a name starting with n. It then removed all other projects. I later added stuff to give read\n",
    "   outs of the total counts of all documents, source forge documents, and gitlab documents\n",
    "   Notes:\n",
    "           --The line that actually did the removal was (line 68) now commented our so its safe to run \n",
    "           --I modified this later so the added source forge repos would be preserved, but at first these would have been\n",
    "             removed\n",
    "           --I once did this with a for loop (line 55) but realized I could accomplish the task \n",
    "             with pymongo function delete many and the comparison query operator $in and a list of the names to keep\n",
    "           --The line 27 created a text index for http_url_to_repo so I could search for specific types of url's\n",
    "             such as gitlab and sourceforge. After I did the adjustments to the collection I added the lines(38, 39)\n",
    "             that show how many different urls of the two types exits in my collection\n",
    "           --As it is now it will tell you total counts of all documents in collection, source forge documents, \n",
    "             and gitlab documents\n",
    "'''\n",
    "import pymongo\n",
    "\n",
    "\n",
    "dbname = \"fdac18mp2\" #please use this database\n",
    "collname = \"glprj_gjones2\" #please modify so you store data in your collection\n",
    "\n",
    "# start pymongo client\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "db = client[dbname]\n",
    "\n",
    "coll = db[collname]\n",
    "\n",
    "# http_url_to_repo\n",
    "\n",
    "# create an index so we can search for url key words\n",
    "#coll.create_index( [( 'http_url_to_repo', \"text\") ] )\n",
    "\n",
    "print('There are {:d} total documents in the collection {:s}'.format(coll.count_documents({}), collname))\n",
    "\n",
    "# grab a cursor to all of the projects\n",
    "#all_projects = coll.find({})\n",
    "\n",
    "# grab a cursor to all projects that start with n\n",
    "n_projects = coll.find({'name': {'$regex': '^n'}})\n",
    "# grabing both gitlab and source forge documents\n",
    "\n",
    "gitlab_projects = coll.find({'$text': {'$search': 'gitlab'}})\n",
    "source_forge_projects = coll.find({'$text': {'$search': 'sourceforge'}})\n",
    "      \n",
    "print('there are {:d} source forge projects'.format(coll.count_documents({'$text': {'$search': 'sourceforge'}})))\n",
    "print('there are {:d} gitlab projects'.format(coll.count_documents({'$text': {'$search': 'gitlab'}})))\n",
    "print('there are {:d} projects that start with n'.format(coll.count_documents({'name': {'$regex': '^n'}})))\n",
    "\n",
    "to_keep_array = list()\n",
    "\n",
    "# load the names of git lab projects starting with n\n",
    "for project in n_projects:\n",
    "    to_keep_array.append(project['name'])\n",
    "\n",
    "#for project in source_forge_projects:\n",
    "    #to_keep_array.append(project['name'])\n",
    "\n",
    "    \n",
    "    \n",
    "# used to count how many projects I have that start with n\n",
    "print(\"the length of the to keep array is {:d}\".format(len(to_keep_array)))\n",
    "   \n",
    "\n",
    "    \n",
    "# delete all project documents that have names \n",
    "# not in the to keep array\n",
    "#coll.delete_many({'name': {'$nin': to_keep_array}})    \n",
    "    \n",
    "    \n",
    "# This for loop \n",
    "#for project in all_projects:\n",
    "#    name = project['name']\n",
    "#    if name not in to_keep_array:\n",
    "#        coll.delete_one({'name': name})\n",
    "   \n",
    "\n",
    "#print('The number of documents in my collection is now {:d}'.format(coll.count_documents({})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original count is 860\n",
      "The dictionary list contains 68\n",
      "The number of names is 68\n",
      "There are 68 entries in dlist\n",
      "The new count is 860\n",
      "Name 1: n-ctrl\n",
      "Name 2: naps\n",
      "Name 3: narxsim\n",
      "Name 4: nas4free\n",
      "Name 5: nasi\n",
      "Name 6: ncron\n",
      "Name 7: ndnbackpropneur\n",
      "Name 8: ndata\n",
      "Name 9: net-simulator\n",
      "Name 10: netvalidator\n",
      "Name 11: neur-php\n",
      "Name 12: nfogen\n",
      "Name 13: ngsmleditor\n",
      "Name 14: ninu\n",
      "Name 15: njmvcopensource\n",
      "Name 16: njpc\n",
      "Name 17: nlview\n",
      "Name 18: nlingo\n",
      "Name 19: nmea\n",
      "Name 20: noperation\n",
      "Name 21: nrrd-cpp\n",
      "Name 22: ns2miraclewimax\n",
      "Name 23: nsisdevprojects\n",
      "Name 24: nwe00xmp3man\n",
      "Name 25: nwn2ata\n",
      "Name 26: nxwtools\n",
      "Name 27: namin\n",
      "Name 28: naivete\n",
      "Name 29: namaless\n",
      "Name 30: napatacms\n",
      "Name 31: narga\n",
      "Name 32: nativecppnetlibrary\n",
      "Name 33: nativelibs4java\n",
      "Name 34: nativeviewer\n",
      "Name 35: nside\n",
      "Name 36: nekit\n",
      "Name 37: neotracker-time\n",
      "Name 38: neoshark-2013\n",
      "Name 39: neptunekrn\n",
      "Name 40: neriaxi\n",
      "Name 41: net4j\n",
      "Name 42: netcvslib\n",
      "Name 43: netdj\n",
      "Name 44: netkit-srl\n",
      "Name 45: nettext\n",
      "Name 46: netbritelibrary\n",
      "Name 47: nethackmodern\n",
      "Name 48: networkemulator\n",
      "Name 49: network-ip-tools\n",
      "Name 50: netperfadvisor\n",
      "Name 51: networkservice\n",
      "Name 52: neuralduino\n",
      "Name 53: neuronhealth\n",
      "Name 54: nexstarctl\n",
      "Name 55: nexuiz-extra\n",
      "Name 56: niamara\n",
      "Name 57: nithilam\n",
      "Name 58: nochatmobile\n",
      "Name 59: nodehrapp\n",
      "Name 60: nodeclipse\n",
      "Name 61: noetext\n",
      "Name 62: nomik\n",
      "Name 63: noora\n",
      "Name 64: norna\n",
      "Name 65: npp-graphbuilder-plugin\n",
      "Name 66: npp-plugins\n",
      "Name 67: novagrid\n",
      "Name 68: nuvarator\n"
     ]
    }
   ],
   "source": [
    "'''The below cell was used to load some source forge  repos.\n",
    "   Other relevant code and Notes:\n",
    "       url_tester: (line 137 method call) The call to this  method was used to test the urls of projects to make sure they \n",
    "                  still existed\n",
    "                   --The call to this code is currently commented out since I already did the tests\n",
    "       get_projects_dict_ffile: (line 95 declaration, 131 method call) creates a list dictionarys from a given file that \n",
    "                                contains urls to source forge project repos added by hand. The dictionary is of the form:\n",
    "                                key=name, val = name of repo\n",
    "                                key=http_url_to_repo, val = url to repo\n",
    "        --line 155: adds the the list of dictionaries to my collection. This line is commented out due to me already running\n",
    "                   this once. \n",
    "'''\n",
    "import sys\n",
    "import re\n",
    "\n",
    "\n",
    "import pymongo\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import pprint\n",
    "\n",
    "\n",
    "dbname = \"fdac18mp2\" #please use this database\n",
    "collname = \"glprj_gjones2\" #please modify so you store data in your collection\n",
    "\n",
    "my_letter = 'n'\n",
    "\n",
    "# start pymongo client\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "# grab reference to the class database\n",
    "db = client[dbname]\n",
    "\n",
    "# grab a reference to my collection\n",
    "coll = db[collname]\n",
    "\n",
    "# check how many documents are in my collection\n",
    "# old_col_count = coll.count_documents({})\n",
    "# print('The original count is {:d}'.format(old_col_count))\n",
    "\n",
    "# will test the urls in d_list and make sure they go \n",
    "# somewhere. If the url doesn't it will be removed\n",
    "def url_tester(d_list):\n",
    "    cnt = 0\n",
    "    bad_cnt = 0\n",
    "    for dictL in d_list:\n",
    "        url = dictL['http_url_to_repo']\n",
    "        name = dictL['name']\n",
    "        r = requests.get(url)\n",
    "        print(r.status_code)\n",
    "        if not r.ok or r.status_code != 200:\n",
    "            print('There is a bad url for project {:s} at url {:s}'.format(name, url))\n",
    "            #TODO: remove bad urls\n",
    "        elif r.status_code == 403:\n",
    "            print('we got blocked!!!!')\n",
    "        cnt +=1\n",
    "        if cnt == 100: \n",
    "            break\n",
    "    return bad_cnt, cnt\n",
    "\n",
    "\n",
    "# grabs the name from a url to a project\n",
    "# and returns it.\n",
    "# used for the source forge urls to get the name of the repo\n",
    "def get_name(url):\n",
    "    stp = len(url)-1\n",
    "    ps =url.find('projects', 0)\n",
    "    fs = url.find('/' ,ps)\n",
    "    strt = fs + 1\n",
    "    return url[strt:stp]\n",
    "\n",
    "\n",
    "# creates a dictionary out of the url\n",
    "# argument were the keys are:\n",
    "# name = name of the project\n",
    "# http_url_to_repo = the url to the repo named 'name'\n",
    "# and returns that dictionary\n",
    "# will be used to create a list of dictionary's that \n",
    "# will be added to my collection\n",
    "def add_projects(url):\n",
    "    dict = {}\n",
    "    # use the get_name method to get the name of the repo\n",
    "    name = get_name(url)\n",
    "    \n",
    "    # make sure the project actually starts with the correct letter\n",
    "    if name[0] == 'n':\n",
    "        dict['name'] = name\n",
    "        dict['http_url_to_repo']=url\n",
    "    return dict\n",
    "\n",
    "# This is what loads the sorce forge projects.\n",
    "# opens and reads the source forge \n",
    "# urls stored in the file named SourceForge_urls.txt\n",
    "# and returns a dictionary list where each entry in \n",
    "# the list is is of the form:\n",
    "#                           name: name of project\n",
    "#                           http_url_to_repo: the url to the repo of the given name\n",
    "# also returns a list of the names of the projects added for debugging\n",
    "def get_projects_dict_ffile(filename, c):\n",
    "\n",
    "    f = open(filename, 'r')\n",
    "\n",
    "\n",
    "    d_list = list()\n",
    "    names = list()\n",
    "    for line in f:\n",
    "        \n",
    "        # create a dictionary where the keys are the tags:\n",
    "        #                                                name: name of project\n",
    "        #                                                http_url_to_repo: the url to the project\n",
    "        # see definition of methond above for more details\n",
    "        n_dict = add_projects(line.strip('\\n'))\n",
    "        \n",
    "        #store the names of the projects\n",
    "        names.append(dict['name'])\n",
    "    \n",
    "        # if add_projects didn't find a project that starts with the\n",
    "        # correct letter it returns a empty dictionary\n",
    "        # if this happens do not add it but alert the user\n",
    "        if len(n_dict) == 0:\n",
    "            print('bad project name at {:d}'.format(c))\n",
    "        else:\n",
    "            d_list.append(n_dict)\n",
    "        c += 1\n",
    "    \n",
    "    return d_list, names\n",
    "\n",
    "# cnt = 1\n",
    "\n",
    "# create a list containing dictionaries representing\n",
    "# the projects and thier urls found in the named file\n",
    "dlist, name_list = get_projects_dict_ffile('SourceForge_urls.txt', 1)\n",
    "\n",
    "\n",
    "\n",
    "# used for debugging and testing\n",
    "#for dict in dlist:\n",
    "#    print(cnt,dict)\n",
    "#    cnt +=1\n",
    "\n",
    "\n",
    "# The below code test the urls loaded to make sure they exist.\n",
    "# test the urls in the dictionary list(dlist) and make sure they still exist \n",
    "# if they do not they are removed\n",
    "# url_tester(dlist)    \n",
    "\n",
    "\n",
    "print('The number of names is {:d}'.format(len(name_list)))\n",
    "print('There are {:d} entries in dlist'.format(len(dlist)))\n",
    "\n",
    "# --------------------------------------------------------------Insert the source forge projects\n",
    "#coll.insert_many(dlist)\n",
    "\n",
    "#new_col_count = coll.count_documents({})\n",
    "#print('The new count is {:d}'.format(new_col_count))\n",
    "\n",
    "# my_add_projects = coll.find({name:{'$s': name_list} })\n",
    "\n",
    "#cntt = 1\n",
    "#for project in coll.find({'name':{'$in': name_list} }):\n",
    "    \n",
    "    #print('Name {:d}: {:s}'.format(cntt, project['name']))\n",
    "    #cntt += 1\n",
    "    \n",
    "#for line in lines:\n",
    "#    print(cnt,line)\n",
    "#    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "there are 0 bad links in the first 792\n"
     ]
    }
   ],
   "source": [
    "'''This cell was used to test the gitlab urls to make sure they worked if they didn't they would be removed.\n",
    "   I repeated this process until i got no bad links back \n",
    "   Notes:\n",
    "         ---The line(32) that once deleted documents that didn't work has been commented out so if you want to test a url\n",
    "             just uncomment it\n",
    "'''\n",
    "\n",
    "# now remove non working links\n",
    "\n",
    "def gitlab_url_tester(collection, limit):\n",
    "\n",
    "    cnt = 0\n",
    "    bad_cnt = 0\n",
    "    to_keep_names = list()\n",
    "\n",
    "    for project in collection.find():\n",
    "        url = project['http_url_to_repo']\n",
    "        name = project['name']\n",
    "        r = requests.get(url)\n",
    "        #print(r.status_code)\n",
    "        if not r.ok or r.status_code != 200:\n",
    "            print('There is a bad url for project {:s} at url {:s}'.format(name, url))\n",
    "            bad_cnt += 1\n",
    "        elif r.status_code == 403:\n",
    "            print('we got blocked!!!!')\n",
    "        else:\n",
    "            to_keep_names.append(name)\n",
    "        cnt +=1\n",
    "        if cnt == limit: \n",
    "            break\n",
    "            \n",
    "    #coll.delete_many({'name': {'$nin': to_keep_names}}) \n",
    "    \n",
    "    return bad_cnt, cnt\n",
    "limit = coll.count_documents({})\n",
    "\n",
    "# Test the urls in collection\n",
    "bad, cnt = gitlab_url_tester(coll, limit)\n",
    "\n",
    "print('there are {:d} bad links in the first {:d}'.format(bad, cnt))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give me which type of projects you want to see:\n",
      "0) source forge projects\n",
      "1) git lab projects\n",
      "What is your choice? 0\n",
      "you chose source forge projects\n",
      "1How many projects would you like to see. Must be between 1 and 6815\n",
      "you chose  to see 15 source forge projects\n",
      "\n",
      "1) name: network-ip-tools, url: https://sourceforge.net/projects/network-ip-tools/\n",
      "2) name: npp-graphbuilder-plugin, url: https://sourceforge.net/projects/npp-graphbuilder-plugin/\n",
      "3) name: n-ctrl, url: https://sourceforge.net/projects/n-ctrl/\n",
      "4) name: net-simulator, url: https://sourceforge.net/projects/net-simulator/\n",
      "5) name: neur-php, url: https://sourceforge.net/projects/neur-php/\n",
      "6) name: nrrd-cpp, url: https://sourceforge.net/projects/nrrd-cpp/\n",
      "7) name: neotracker-time, url: https://sourceforge.net/projects/neotracker-time/\n",
      "8) name: neoshark-2013, url: https://sourceforge.net/projects/neoshark-2013/\n",
      "9) name: netkit-srl, url: https://sourceforge.net/projects/netkit-srl/\n",
      "10) name: nexuiz-extra, url: https://sourceforge.net/projects/nexuiz-extra/\n",
      "11) name: npp-plugins, url: https://sourceforge.net/projects/npp-plugins/\n",
      "12) name: naps, url: https://sourceforge.net/projects/naps/\n",
      "13) name: narxsim, url: https://sourceforge.net/projects/narxsim/\n",
      "14) name: nas4free, url: https://sourceforge.net/projects/nas4free/\n",
      "15) name: nasi, url: https://sourceforge.net/projects/nasi/\n"
     ]
    }
   ],
   "source": [
    "'''    This cell of code will allow the user to look at the different project names and url\n",
    "       stored in my collection. It prompts the user to give a numeric choice of 0(source forge)\n",
    "       or 1(gitlab) and the prompts the user to enter how many of that type they would like to see.\n",
    "       This was mainly used for debugging and messing around with pymongo\n",
    "'''\n",
    "import pymongo\n",
    "\n",
    "\n",
    "dbname = \"fdac18mp2\" #please use this database\n",
    "collname = \"glprj_gjones2\" #please modify so you store data in your collection\n",
    "\n",
    "\n",
    "# start pymongo client\n",
    "client = pymongo.MongoClient()\n",
    "\n",
    "options = ['0', '1']\n",
    "p_types = ['source forge projects', 'git lab projects']\n",
    "\n",
    "project_type = ''\n",
    "\n",
    "while project_type != '0' and project_type != '1':\n",
    "    print('Give me which type of projects you want to see:')\n",
    "    print('0) source forge projects')\n",
    "    print('1) git lab projects')\n",
    "    project_type = input(\"What is your choice? \")\n",
    "    print('you chose {:s}'.format(p_types[int(project_type)]))\n",
    "\n",
    "\n",
    "    \n",
    "limit = 0\n",
    "\n",
    "choice = '-1'\n",
    "\n",
    "if int(project_type) == 0:\n",
    "    projects = coll.find({'$text': {'$search': 'sourceforge'}})\n",
    "    limit = coll.count_documents({'$text': {'$search': 'sourceforge'}})\n",
    "    \n",
    "    while int(choice) <= 0 and int(choice) < limit:\n",
    "    #while int(choice) not in options:\n",
    "        choice = input('1How many projects would you like to see. Must be between 1 and {:d}'.format(limit))     \n",
    "else:\n",
    "    projects = coll.find({'$text': {'$search': 'gitlab'}})\n",
    "    limit = coll.count_documents({'$text': {'$search': 'gitlab'}})\n",
    "    \n",
    "    while int(choice) <= 0 and int(choice) < limit:\n",
    "        choice = input('How many projects would you like to see. Must be between 1 and {:d}: '.format(limit))\n",
    "\n",
    "print('you chose  to see {:d} {:s}'.format(int(choice), p_types[int(project_type)]))\n",
    "print('')      \n",
    "\n",
    "cnt = 1\n",
    "for project in projects:\n",
    "    print('{:d}) name: {:s}, url: {:s}'.format(cnt, project['name'], project['http_url_to_repo']))\n",
    "    cnt += 1\n",
    "    if cnt > int(choice):\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of documents in my collection is:\n",
      "792\n",
      "the number of elements in to keep array is:\n",
      "792\n"
     ]
    }
   ],
   "source": [
    "print('The number of documents in my collection is:')\n",
    "print(coll.count_documents({}))\n",
    "print('the number of elements in to keep array is:')\n",
    "print(len(to_keep_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
